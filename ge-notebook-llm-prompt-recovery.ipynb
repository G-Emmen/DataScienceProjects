{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9b5c46",
   "metadata": {
    "papermill": {
     "duration": 0.004284,
     "end_time": "2024-02-29T01:41:54.039568",
     "exception": false,
     "start_time": "2024-02-29T01:41:54.035284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GE Notebook - LLM Prompt Recovery\n",
    "\n",
    "Let's start by defining the scope of the work:\n",
    "\n",
    "- Understand the Problem\n",
    "- Understand the data\n",
    "- Prepare the data\n",
    "- Feature Engineering\n",
    "- Modelling\n",
    "- Evaluation\n",
    "- Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273a8b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T01:41:54.048173Z",
     "iopub.status.busy": "2024-02-29T01:41:54.047861Z",
     "iopub.status.idle": "2024-02-29T01:41:54.753481Z",
     "shell.execute_reply": "2024-02-29T01:41:54.752683Z"
    },
    "papermill": {
     "duration": 0.712544,
     "end_time": "2024-02-29T01:41:54.755905",
     "exception": false,
     "start_time": "2024-02-29T01:41:54.043361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912de8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T01:41:54.764879Z",
     "iopub.status.busy": "2024-02-29T01:41:54.764488Z",
     "iopub.status.idle": "2024-02-29T01:43:20.003980Z",
     "shell.execute_reply": "2024-02-29T01:43:20.002889Z"
    },
    "papermill": {
     "duration": 85.246651,
     "end_time": "2024-02-29T01:43:20.006476",
     "exception": false,
     "start_time": "2024-02-29T01:41:54.759825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Setup the environment\n",
    "!pip install -q -U immutabledict sentencepiece \n",
    "!git clone https://github.com/google/gemma_pytorch.git\n",
    "!mkdir /kaggle/working/gemma/\n",
    "!mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/gemma/\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"/kaggle/working/gemma_pytorch/\") \n",
    "from gemma.config import GemmaConfig, get_config_for_7b, get_config_for_2b\n",
    "from gemma.model import GemmaForCausalLM\n",
    "from gemma.tokenizer import Tokenizer\n",
    "import contextlib\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "VARIANT = \"7b-it-quant\" \n",
    "MACHINE_TYPE = \"cuda\" \n",
    "weights_dir = '/kaggle/input/gemma/pytorch/7b-it-quant/2' \n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "  \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
    "  torch.set_default_dtype(dtype)\n",
    "  yield\n",
    "  torch.set_default_dtype(torch.float)\n",
    "\n",
    "# Model Config.\n",
    "model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()\n",
    "model_config.tokenizer = os.path.join(weights_dir, \"tokenizer.model\")\n",
    "model_config.quant = \"quant\" in VARIANT\n",
    "\n",
    "# Model.\n",
    "device = torch.device(MACHINE_TYPE)\n",
    "with _set_default_tensor_type(model_config.get_dtype()):\n",
    "  model = GemmaForCausalLM(model_config)\n",
    "  ckpt_path = os.path.join(weights_dir, f'gemma-{VARIANT}.ckpt')\n",
    "  model.load_weights(ckpt_path)\n",
    "  model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f093c",
   "metadata": {
    "papermill": {
     "duration": 0.003556,
     "end_time": "2024-02-29T01:43:20.014122",
     "exception": false,
     "start_time": "2024-02-29T01:43:20.010566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Understand the Problem\n",
    "\n",
    "> LLMs are commonly used to rewrite or make stylistic changes to text. The goal of this competition is to recover the LLM prompt that was used to transform a given text.\n",
    "> \n",
    "> NLP workflows increasingly involve rewriting text, but there's still a lot to learn about how to prompt LLMs effectively. This machine learning competition is designed to be a novel way to dig deeper into this problem.\n",
    "> \n",
    "> The challenge: recover the LLM prompt used to rewrite a given text. You’ll be tested against a dataset of 1300+ original texts, each paired with a rewritten version from Gemma, Google’s new family of open models.\n",
    "\n",
    "This problem includes a free-form start where contestants have to define and build their own training data. The example submissions give a hint as to what we should be looking for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82eae55",
   "metadata": {
    "papermill": {
     "duration": 0.003405,
     "end_time": "2024-02-29T01:43:20.021044",
     "exception": false,
     "start_time": "2024-02-29T01:43:20.017639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Understand the Data\n",
    "\n",
    "This competition has examples of testing/training data, but doesn't include any form of large dataset to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8466b799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T01:43:20.030007Z",
     "iopub.status.busy": "2024-02-29T01:43:20.029351Z",
     "iopub.status.idle": "2024-02-29T01:43:21.752557Z",
     "shell.execute_reply": "2024-02-29T01:43:21.751725Z"
    },
    "papermill": {
     "duration": 1.730264,
     "end_time": "2024-02-29T01:43:21.754903",
     "exception": false,
     "start_time": "2024-02-29T01:43:20.024639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    'Rewrite this in the style of William Shakespeare',\n",
    "    'Rewrite this in the style Dr. Seuss',\n",
    "    'Rewrite this in the style of Beyonce',\n",
    "    'Rewrite this in the style of Edgar Allen Poe',\n",
    "    'Rewrite this as a poem',\n",
    "    'Rewrite this with more emotion',\n",
    "    'Rewrite this as a tweet from a teenager',\n",
    "    'Rewrite this as a presidential announcement',\n",
    "    'Rewrite this as if a dog wrote it',\n",
    "    'Rewrite this as if a cat wrote it',\n",
    "    'Rewrite this as a haiku',\n",
    "    'Improve this text',\n",
    "    'Simplify this text',\n",
    "    'Add complexity to this text',\n",
    "    'Rewrite this text',\n",
    "    'Could you change this text?',\n",
    "    'Can you change this text?',\n",
    "    'Write this differently',\n",
    "    'Remove all emotion from this text',\n",
    "    'Rewrite this text to avoid plagairism'\n",
    "]\n",
    "\n",
    "df_movie_plot = pd.read_csv('/kaggle/input/wikipedia-movie-plots/wiki_movie_plots_deduped.csv')\n",
    "\n",
    "phrases = df_movie_plot[['Plot']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c881c5d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T01:43:21.764633Z",
     "iopub.status.busy": "2024-02-29T01:43:21.764012Z",
     "iopub.status.idle": "2024-02-29T02:52:11.599548Z",
     "shell.execute_reply": "2024-02-29T02:52:11.598637Z"
    },
    "papermill": {
     "duration": 4129.84287,
     "end_time": "2024-02-29T02:52:11.601984",
     "exception": false,
     "start_time": "2024-02-29T01:43:21.759114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the prompt format the model expects\n",
    "USER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "\n",
    "number_of_rewrites = 5\n",
    "\n",
    "rewrite_data = []\n",
    "\n",
    "for phrase in phrases:\n",
    "    for prompt in prompts:\n",
    "        prompt = f'{prompt}\\n{phrase}'\n",
    "        for i in range(number_of_rewrites):\n",
    "            rewritten_text = model.generate(\n",
    "                USER_CHAT_TEMPLATE.format(prompt=prompt),\n",
    "                device=device,\n",
    "                output_len=100,\n",
    "            )\n",
    "            rewrite_data.append({\n",
    "                'phrase': phrase,\n",
    "                'prompt': prompt,\n",
    "                'rewritten_text': rewritten_text,\n",
    "            }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f25f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T02:52:11.611218Z",
     "iopub.status.busy": "2024-02-29T02:52:11.610907Z",
     "iopub.status.idle": "2024-02-29T02:52:11.626240Z",
     "shell.execute_reply": "2024-02-29T02:52:11.625464Z"
    },
    "papermill": {
     "duration": 0.02215,
     "end_time": "2024-02-29T02:52:11.628176",
     "exception": false,
     "start_time": "2024-02-29T02:52:11.606026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plot</td>\n",
       "      <td>Rewrite this in the style of William Shakespea...</td>\n",
       "      <td>Sure, here's the rewritten portion of text in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot</td>\n",
       "      <td>Rewrite this in the style of William Shakespea...</td>\n",
       "      <td>Sure, here's the rewritten text in the style o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot</td>\n",
       "      <td>Rewrite this in the style of William Shakespea...</td>\n",
       "      <td>Sure, here's the rewritten text in the style o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plot</td>\n",
       "      <td>Rewrite this in the style of William Shakespea...</td>\n",
       "      <td>Sure, here's the rewritten text in the style o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plot</td>\n",
       "      <td>Rewrite this in the style of William Shakespea...</td>\n",
       "      <td>Sure, here's the rewritten text in the style o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  phrase                                             prompt  \\\n",
       "0   Plot  Rewrite this in the style of William Shakespea...   \n",
       "1   Plot  Rewrite this in the style of William Shakespea...   \n",
       "2   Plot  Rewrite this in the style of William Shakespea...   \n",
       "3   Plot  Rewrite this in the style of William Shakespea...   \n",
       "4   Plot  Rewrite this in the style of William Shakespea...   \n",
       "\n",
       "                                      rewritten_text  \n",
       "0  Sure, here's the rewritten portion of text in ...  \n",
       "1  Sure, here's the rewritten text in the style o...  \n",
       "2  Sure, here's the rewritten text in the style o...  \n",
       "3  Sure, here's the rewritten text in the style o...  \n",
       "4  Sure, here's the rewritten text in the style o...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(rewrite_data)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b845337",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T02:52:11.682788Z",
     "iopub.status.busy": "2024-02-29T02:52:11.682449Z",
     "iopub.status.idle": "2024-02-29T02:52:11.691586Z",
     "shell.execute_reply": "2024-02-29T02:52:11.690698Z"
    },
    "papermill": {
     "duration": 0.016405,
     "end_time": "2024-02-29T02:52:11.693695",
     "exception": false,
     "start_time": "2024-02-29T02:52:11.677290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_csv_path = 'LLM_train_output.csv'\n",
    "df_train.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9518e7",
   "metadata": {
    "papermill": {
     "duration": 0.003913,
     "end_time": "2024-02-29T02:52:11.701683",
     "exception": false,
     "start_time": "2024-02-29T02:52:11.697770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare the Data\n",
    "\n",
    "Take the generated data, and process it for use in modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4930b5b",
   "metadata": {
    "papermill": {
     "duration": 0.003767,
     "end_time": "2024-02-29T02:52:11.709385",
     "exception": false,
     "start_time": "2024-02-29T02:52:11.705618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Explore steps for processing data to improve modelling. Outlier rejection, data scaling, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f26fb9",
   "metadata": {
    "papermill": {
     "duration": 0.00366,
     "end_time": "2024-02-29T02:52:11.717032",
     "exception": false,
     "start_time": "2024-02-29T02:52:11.713372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modelling\n",
    "\n",
    "Create the model and such that will be used for the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d32e75",
   "metadata": {
    "papermill": {
     "duration": 0.004061,
     "end_time": "2024-02-29T02:52:11.724983",
     "exception": false,
     "start_time": "2024-02-29T02:52:11.720922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Use the problem definition to evaluate the model against a private test dataset."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 64890,
     "sourceId": 127736,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 8749,
     "sourceId": 11359,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4221.633343,
   "end_time": "2024-02-29T02:52:12.957732",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-29T01:41:51.324389",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
