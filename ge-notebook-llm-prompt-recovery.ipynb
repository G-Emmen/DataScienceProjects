{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7081ed74",
   "metadata": {
    "papermill": {
     "duration": 0.005669,
     "end_time": "2024-02-29T22:21:25.951763",
     "exception": false,
     "start_time": "2024-02-29T22:21:25.946094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GE Notebook - LLM Prompt Recovery\n",
    "\n",
    "Let's start by defining the scope of the work:\n",
    "\n",
    "- Understand the Problem\n",
    "- Understand the data\n",
    "- Prepare the data\n",
    "- Feature Engineering\n",
    "- Modelling\n",
    "- Evaluation\n",
    "- Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b179cfe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:21:25.961779Z",
     "iopub.status.busy": "2024-02-29T22:21:25.961385Z",
     "iopub.status.idle": "2024-02-29T22:21:26.680893Z",
     "shell.execute_reply": "2024-02-29T22:21:26.680126Z"
    },
    "papermill": {
     "duration": 0.727176,
     "end_time": "2024-02-29T22:21:26.683218",
     "exception": false,
     "start_time": "2024-02-29T22:21:25.956042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1aa344c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:21:26.693028Z",
     "iopub.status.busy": "2024-02-29T22:21:26.692641Z",
     "iopub.status.idle": "2024-02-29T22:22:46.732742Z",
     "shell.execute_reply": "2024-02-29T22:22:46.731837Z"
    },
    "papermill": {
     "duration": 80.047738,
     "end_time": "2024-02-29T22:22:46.735319",
     "exception": false,
     "start_time": "2024-02-29T22:21:26.687581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Setup the environment\n",
    "!pip install -q -U immutabledict sentencepiece \n",
    "!git clone https://github.com/google/gemma_pytorch.git\n",
    "!mkdir /kaggle/working/gemma/\n",
    "!mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/gemma/\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"/kaggle/working/gemma_pytorch/\") \n",
    "from gemma.config import GemmaConfig, get_config_for_7b, get_config_for_2b\n",
    "from gemma.model import GemmaForCausalLM\n",
    "from gemma.tokenizer import Tokenizer\n",
    "import contextlib\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "VARIANT = \"7b-it-quant\" \n",
    "MACHINE_TYPE = \"cuda\" \n",
    "weights_dir = '/kaggle/input/gemma/pytorch/7b-it-quant/2' \n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "  \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
    "  torch.set_default_dtype(dtype)\n",
    "  yield\n",
    "  torch.set_default_dtype(torch.float)\n",
    "\n",
    "# Model Config.\n",
    "model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()\n",
    "model_config.tokenizer = os.path.join(weights_dir, \"tokenizer.model\")\n",
    "model_config.quant = \"quant\" in VARIANT\n",
    "\n",
    "# Model.\n",
    "device = torch.device(MACHINE_TYPE)\n",
    "with _set_default_tensor_type(model_config.get_dtype()):\n",
    "  model = GemmaForCausalLM(model_config)\n",
    "  ckpt_path = os.path.join(weights_dir, f'gemma-{VARIANT}.ckpt')\n",
    "  model.load_weights(ckpt_path)\n",
    "  model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44b32e",
   "metadata": {
    "papermill": {
     "duration": 0.003943,
     "end_time": "2024-02-29T22:22:46.743846",
     "exception": false,
     "start_time": "2024-02-29T22:22:46.739903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Understand the Problem\n",
    "\n",
    "> LLMs are commonly used to rewrite or make stylistic changes to text. The goal of this competition is to recover the LLM prompt that was used to transform a given text.\n",
    "> \n",
    "> NLP workflows increasingly involve rewriting text, but there's still a lot to learn about how to prompt LLMs effectively. This machine learning competition is designed to be a novel way to dig deeper into this problem.\n",
    "> \n",
    "> The challenge: recover the LLM prompt used to rewrite a given text. You’ll be tested against a dataset of 1300+ original texts, each paired with a rewritten version from Gemma, Google’s new family of open models.\n",
    "\n",
    "This problem includes a free-form start where contestants have to define and build their own training data. The example submissions give a hint as to what we should be looking for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854e8db0",
   "metadata": {
    "papermill": {
     "duration": 0.004022,
     "end_time": "2024-02-29T22:22:46.751889",
     "exception": false,
     "start_time": "2024-02-29T22:22:46.747867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Understand the Data\n",
    "\n",
    "This competition has examples of testing/training data, but doesn't include any form of large dataset to train with. We have to make our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83fcf889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:22:46.761611Z",
     "iopub.status.busy": "2024-02-29T22:22:46.761126Z",
     "iopub.status.idle": "2024-02-29T22:22:46.780177Z",
     "shell.execute_reply": "2024-02-29T22:22:46.779428Z"
    },
    "papermill": {
     "duration": 0.026236,
     "end_time": "2024-02-29T22:22:46.782119",
     "exception": false,
     "start_time": "2024-02-29T22:22:46.755883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the input CSV containing 100 ChatGPT generated \"rewrite this as...\" prompts\n",
    "df_rewrite_prompts = pd.read_csv('/kaggle/input/rewrite-prompts/rewrite_prompts.csv')\n",
    "\n",
    "# convert the 'Rewrite Prompt' column to a list\n",
    "prompt_list = df_rewrite_prompts['Rewrite Prompt'].to_list()\n",
    "\n",
    "# select a number of random prompts to pull from the list\n",
    "number_of_prompts = 10\n",
    "prompt_selector = random.sample(range(0,len(prompt_list)),number_of_prompts)\n",
    "\n",
    "# create a blank list for the prompts that will be used to build onto the training dataset\n",
    "prompts = []\n",
    "\n",
    "# add the randomly selected prompts to the final list\n",
    "for i in prompt_selector:\n",
    "    prompts.append(prompt_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2158c076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:22:46.791250Z",
     "iopub.status.busy": "2024-02-29T22:22:46.790977Z",
     "iopub.status.idle": "2024-02-29T22:23:11.234592Z",
     "shell.execute_reply": "2024-02-29T22:23:11.233588Z"
    },
    "papermill": {
     "duration": 24.45081,
     "end_time": "2024-02-29T22:23:11.236941",
     "exception": false,
     "start_time": "2024-02-29T22:22:46.786131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the input CSV containing both AI and human generated text\n",
    "df_movie_plot = pd.read_csv('/kaggle/input/ai-vs-human-text/AI_Human.csv')\n",
    "\n",
    "# convert the 'text' column to a list   \n",
    "phrase_list = df_movie_plot['text'].to_list()\n",
    "\n",
    "# select a number of random phrases to pull from the list\n",
    "number_of_phrases = 10\n",
    "phrase_selector = random.sample(range(0,len(phrase_list)),number_of_phrases)\n",
    "\n",
    "# create a blank list for the phrases that will be used to build onto the training dataset\n",
    "phrases = []\n",
    "\n",
    "# add the randomly selected phrases to the final list\n",
    "for i in phrase_selector:\n",
    "    phrases.append(phrase_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e405ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T22:23:11.247077Z",
     "iopub.status.busy": "2024-02-29T22:23:11.246759Z",
     "iopub.status.idle": "2024-03-01T04:18:10.650211Z",
     "shell.execute_reply": "2024-03-01T04:18:10.649344Z"
    },
    "papermill": {
     "duration": 21299.411237,
     "end_time": "2024-03-01T04:18:10.652827",
     "exception": false,
     "start_time": "2024-02-29T22:23:11.241590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the prompt format the model expects\n",
    "USER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "\n",
    "number_of_tries = 5\n",
    "\n",
    "rewrite_data = []\n",
    "\n",
    "for phrase in phrases:\n",
    "    for prompt in prompts:\n",
    "        prompt = f'{prompt}\\n{phrase}'\n",
    "        for n in range(number_of_tries):\n",
    "            rewritten_text = model.generate(\n",
    "                USER_CHAT_TEMPLATE.format(prompt=prompt),\n",
    "                device=device,\n",
    "                output_len=100,\n",
    "            )\n",
    "            rewrite_data.append({\n",
    "                'phrase': phrase,\n",
    "                'prompt': prompt,\n",
    "                'rewritten_text': rewritten_text,\n",
    "            }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce0c4d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T04:18:10.663156Z",
     "iopub.status.busy": "2024-03-01T04:18:10.662847Z",
     "iopub.status.idle": "2024-03-01T04:18:10.678216Z",
     "shell.execute_reply": "2024-03-01T04:18:10.677337Z"
    },
    "papermill": {
     "duration": 0.022789,
     "end_time": "2024-03-01T04:18:10.680320",
     "exception": false,
     "start_time": "2024-03-01T04:18:10.657531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sometimes talking to more than one person get ...</td>\n",
       "      <td>Imbue this with a dash of F. Scott Fitzgerald\\...</td>\n",
       "      <td>Sure, here's the text infused with a dash of F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sometimes talking to more than one person get ...</td>\n",
       "      <td>Imbue this with a dash of F. Scott Fitzgerald\\...</td>\n",
       "      <td>Sure, here's the text infused with a dash of F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sometimes talking to more than one person get ...</td>\n",
       "      <td>Imbue this with a dash of F. Scott Fitzgerald\\...</td>\n",
       "      <td>Sure, here's the text infused with a dash of F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sometimes talking to more than one person get ...</td>\n",
       "      <td>Imbue this with a dash of F. Scott Fitzgerald\\...</td>\n",
       "      <td>A toast to the transformative power of engagin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sometimes talking to more than one person get ...</td>\n",
       "      <td>Imbue this with a dash of F. Scott Fitzgerald\\...</td>\n",
       "      <td>Sure, here's the text imbued with a dash of F....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase  \\\n",
       "0  sometimes talking to more than one person get ...   \n",
       "1  sometimes talking to more than one person get ...   \n",
       "2  sometimes talking to more than one person get ...   \n",
       "3  sometimes talking to more than one person get ...   \n",
       "4  sometimes talking to more than one person get ...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Imbue this with a dash of F. Scott Fitzgerald\\...   \n",
       "1  Imbue this with a dash of F. Scott Fitzgerald\\...   \n",
       "2  Imbue this with a dash of F. Scott Fitzgerald\\...   \n",
       "3  Imbue this with a dash of F. Scott Fitzgerald\\...   \n",
       "4  Imbue this with a dash of F. Scott Fitzgerald\\...   \n",
       "\n",
       "                                      rewritten_text  \n",
       "0  Sure, here's the text infused with a dash of F...  \n",
       "1  Sure, here's the text infused with a dash of F...  \n",
       "2  Sure, here's the text infused with a dash of F...  \n",
       "3  A toast to the transformative power of engagin...  \n",
       "4  Sure, here's the text imbued with a dash of F....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(rewrite_data)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3462f732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T04:18:10.691322Z",
     "iopub.status.busy": "2024-03-01T04:18:10.691002Z",
     "iopub.status.idle": "2024-03-01T04:18:10.812743Z",
     "shell.execute_reply": "2024-03-01T04:18:10.811978Z"
    },
    "papermill": {
     "duration": 0.129958,
     "end_time": "2024-03-01T04:18:10.815102",
     "exception": false,
     "start_time": "2024-03-01T04:18:10.685144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_csv_path = f'LLM_train_output_{datetime.datetime.now().strftime(\"%H%M_%m%d%Y\")}.csv'\n",
    "df_train.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff5b391",
   "metadata": {
    "papermill": {
     "duration": 0.004291,
     "end_time": "2024-03-01T04:18:10.824252",
     "exception": false,
     "start_time": "2024-03-01T04:18:10.819961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare the Data\n",
    "\n",
    "Take the generated data, and process it for use in modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d2042",
   "metadata": {
    "papermill": {
     "duration": 0.004246,
     "end_time": "2024-03-01T04:18:10.833184",
     "exception": false,
     "start_time": "2024-03-01T04:18:10.828938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Explore steps for processing data to improve modelling. Outlier rejection, data scaling, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab69a8d",
   "metadata": {
    "papermill": {
     "duration": 0.004178,
     "end_time": "2024-03-01T04:18:10.841912",
     "exception": false,
     "start_time": "2024-03-01T04:18:10.837734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modelling\n",
    "\n",
    "Create the model and such that will be used for the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58451d3",
   "metadata": {
    "papermill": {
     "duration": 0.004157,
     "end_time": "2024-03-01T04:18:10.850444",
     "exception": false,
     "start_time": "2024-03-01T04:18:10.846287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Use the problem definition to evaluate the model against a private test dataset."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 4288635,
     "sourceId": 7379779,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4518083,
     "sourceId": 7731834,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 8749,
     "sourceId": 11359,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21410.149522,
   "end_time": "2024-03-01T04:18:13.307219",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-29T22:21:23.157697",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
